新聞、謊言、假影片 : 人工智慧讓每一個人都能輕易篡改影音，最大的威脅將是我們不再相信任何事。
2018年4月，網路上出現一段美國前任總統歐巴馬的新影片，背景裡有美國的國旗與總統旗，看起來就像他以前的諸多談話影片。穿著平整的白襯衫與深色西裝，歐巴馬面對攝影機，伸出雙手來強調自己說的話：「川普總統是不折不扣的笨蛋。」
沒有露出一絲笑容，他繼續說：「嘿，你們知道，我從來不說這些話，至少不會是公開演說，但其他人會。」這時畫面分割成兩半，演員皮爾（JordanPeele）出現了，歐巴馬沒有說任何話──這段影片是融合皮爾的模仿與歐巴馬的實際演說而成。兩人並列的畫面繼續傳遞著訊息，這時皮爾就像數位時代的腹語師，把更多話假借歐巴馬的嘴說出。
在假新聞肆虐的這個年代，這段影片是BuzzFeed新聞所製作的公共服務宣導，展示了應用人工智慧（artificialintelligence,AI）新技術的應用程式，它修改影音的方式就像Photoshop處理數位影像一樣：可讓人們篡改事實。
影片還相當粗略。仔細觀看並聆聽，會發現歐巴馬的聲音帶有鼻音，他的嘴（融合了皮爾的嘴）在幾個短暫片刻會偏離中心晃動。但是這項技術（為了好萊塢電影剪輯師和電玩廠商所設計）快速進展，已讓一些國家安全專家和媒體專家想到科技黑暗面。這些工具或許有一天能憑空創造出令人信服的假影片──並非像歐巴馬的談話那般修改自既有的影片，而是精心安排且從未發生過的情節。
假影片對大眾認知與公共論述可能造成深遠的影響。例如美國今年11月舉行的期中選舉，假如勢均力敵的選戰中有一部假影片抹黑了某位政治人物，試想所造成的衝擊；或者某企業公開發行股票的前一晚，執行長遇襲；或是一群人假裝發動恐怖攻擊，欺騙新聞媒體報導，進而引發人們本能般的報復。儘管某部瘋傳的影片後來證實是假的，大眾會不會依舊相信影片內容為真？或許最令人困擾的是：如果造假成為常態，讓我們不再相信多數看到或聽到的事物，包括真相，那該怎麼辦？
很多科技專家體認到AI生成影片技術可能大量濫用。美國史丹佛大學法律教授波西利（NatePersily）表示，科技專家把焦點放在「偵測假影音的解決方案時，反倒很少花時間釐清這些方案是否讓人們不再相信假影片。」波西利研究的一項主題是網路如何影響民主，他和一群研究人員主張，單靠技術方面的解決方案，無法成功遏止瘋傳的假資訊（disinformation）。遏止假資訊需要心理學家、社會科學家和媒體專家共同出力，協助思索這項AI技術如何在真實世界中落實。
波西利說：「我們現在就必須做到這一點，因為科技專家此時（必然會）主導AI生成影片可能導致後果的討論。」我們對於政府和新聞業這類民主機制的信任已經減弱。既然社群媒體是假資訊的主要傳播管道，今天發佈假新聞的人更可輕易利用我們了。沒有適當的解決方案來因應漸趨成熟的技術，我們脆弱的集體信任將面臨更大的危機。
電腦虛構場景
假影片的發展可追溯到1960年代，人們第一次想到可以利用電腦製作影像。1980年代，這些特效成為主流，影迷看著這項技術與時俱進，從科幻電影到1994年「阿甘正傳」（ForrestGump）主角阿甘跟美國總統甘迺迪握了手，2016年「星際大戰外傳：俠盜一號」（RogueOne）則是讓已過世的演員庫興（PeterCushing）和費雪（CarrieFisher）身影重現。南加州大學的資訊科學助理教授黎顥（HaoLi）是擴增實境（AR）新創公司Pinscreen執行長，他表示，這項技術的目標一直是「創造可以上演任何故事的數位世界。我們如何能創造看似真實的東西，但實際上都是虛擬的？」
早期，這些圖像大多出自藝術家，他們使用電腦建立3D模型，然後手工繪製紋路與其他細節；這個過程冗長，無法擴大規模。大約20年前，一些電腦視覺研究人員開始以不同方式思考圖像：與其花時間在個別模型上，何不教電腦根據資料建立模型？1997年，美國區間研發公司（IntervalResearchCorporation）的科學家開發出「影片重寫」（VideoRewrite）軟體，能把既有影片分割成片段，然後重新編排。研究人員製作了一小段影片，內容是甘迺迪說：「我從未跟阿甘見過面。」不久之後，德國馬克士普朗克生物模控研究所的科學家教導電腦從200張人臉的3D掃描資料集裡抓取特徵，然後製作新的臉孔影像。
近來隨著一種名為深度學習（deeplearning）的AI進展，電腦視覺、資料與自動化之間最大的突破應該是在2012年。1990年代晚期的研究是使用靜態資料，而且並未改善；深度學習則不同，不但可調整功能，而且會漸入佳境。德國馬克士普朗克科學史研究所的博士後研究員李曉昌（XiaochangLi，音譯）表示，這項技術把臉孔影像這類物件簡化成位元資料，「這時工程師會說，我們不再依據某物建立模型。我們對某物一無所知，只是運算資料來了解模式、建立模型。」
深度學習使用一道道簡單的數學方程式，其數學模型稱為類神經網路（neuralnetwork），深度學習隨著時間精通任務。例如資訊科學家可以教深度學習工具辨識人臉，方法是輸入成千上萬張影像，而且逐次說明「這是一張臉」或「這不是一張臉」。之後，當這種工具接收到新的人臉影像，就能辨識出構成人臉特徵的模式，然後（從統計上）回應「這也是一張臉」。
接續推出的新技術能夠虛構出看起來像真人臉孔的影像，其深度學習工具就是所謂的生成網路（generativenetwork）。運用的是相同邏輯：資訊科學家以成千上萬張影像來訓練生成網路，但生成網路是根據從範例中蒐集的模式來製作新臉孔影像。現在有些公司使用相同的策略來處理音檔。今年稍早，Google發表Duplex，它是基於WaveNet軟體的AI助理；Duplex能撥打電話，聽起來像真人說話，還會加上語氣停頓，例如「呃」、「嗯」。將來，製作政客的假影片或許就不需要皮爾這類演員。去年4月時，加拿大新創公司Lyrebird發表了音檔範例，聽起來就像歐巴馬、川普、希拉蕊在說話，令人不寒而慄。
但生成網路需要巨量資料集進行訓練，這可能耗費大量人力。改善虛構內容的下一步是教AI訓練自己。2014年，加拿大蒙特婁大學的研究人員以生成對抗網路（generativeadversarialnetwork,GAN）做到這一點，方法是讓兩個類神經網路進行對抗。其一是生成網路，負責製作假影像，另一是鑑別網路，學習辨別影像的真偽。在幾乎沒人監督的情況下，GAN透過對抗方式訓練彼此；鑑別網路辨別生成網路所製作越來越逼真的假影像，而生成網路不斷想騙過鑑別網路。GAN可以製作任何數位內容。加州大學柏克萊分校的科學家發展出一種GAN，可以把馬的影像變成斑馬影像，或是把莫內這類印象派藝術家的畫作變成如相片般真實的景色。
今年5月，德國馬克士普朗克資訊學研究所的研究人員和同事發表了「深度影片」（deepvideo），也是使用某種GAN。深度影片能讓演員控制錄製影片裡其他人的嘴、眼和臉部動作，目前只能在肖像姿態（也就是一個人直視攝影機）下運作；如果演員頭部擺動的幅度太大，影片會有明顯的瑕疵，例如人臉影像周圍出現模糊的像素。
GAN還無法在影片中建構複雜的場景，一如影片所呈現的真實場景。有時，GAN會在影像中虛構出奇怪的東西，例如人的額頭有眼珠。不過今年2月，輝達（NVIDIA）公司的研究人員找到方法，讓GAN能製作出高解析度的臉孔影像；他們先以解析度相對較小的相片訓練GAN，然後由GAN逐步提高解析度。南加州大學的黎顥團隊已經使用GAN製作出逼真的皮膚、牙齒和嘴巴影像，這些都是數位方法難以重建的部位。
