猜猜看，我是機器還是人？ : 電腦程式已能取巧通過分辨人工智慧的涂林測試，因此科學家絞盡腦汁提出新的評估方法，讓智慧機器協助人類實踐探索太空、解譯大腦等夢想！
1950年涂林（AlanTuring）設計出一套想像實驗，從此被視為人工智慧（AI）的終極測試。他稱該實驗為「模仿遊戲」，但大部份人稱為「涂林測試」。涂林預期電腦程式能假裝成人類（像是現在的聊天機器人），回答關於詩歌的問題，或故意犯下計算錯誤，欺騙人類裁判誤認它是人類。然而在科學家眼中，通過涂林測試就像渡過盧比孔河（CrossingtheRubicon，編按：典故是越過邊界、局勢改觀、無法回頭，亦引申為破斧沉舟）一樣，標誌真正的AI到來，但真的是這樣嗎？如果動機錯誤，渡過盧比孔河其實不難：現有科技已能做出暫時欺騙人類的機器人，但這種勝利轉瞬成空，而且離真正的AI還很遙遠。
問題是在涂林測試中太容易取巧了，只要蓄意欺騙或假裝無知便能「獲勝」。涂林在某種程度上也體認到，獲勝的訣竅在於不要正面回答問題。如果裁判詢問機器：「你有知覺嗎？」機器必須說謊才能獲勝。但這怪象不是例外，而是規則。換句話說，通過涂林測試的途徑就是欺騙。
電腦也作弊
2014年，聊天機器人古斯特曼（EugeneGoostman）被設定成是來自烏克蘭敖德薩的13歲男孩，喜歡挖苦人、也從未正面回答問題，據說通過了涂林測試。約有1/3的裁判被騙，足夠它宣稱獲得表面勝利。但那又怎麼樣？裁判只和它對話了幾分鐘，如果時間充裕，毫無疑問他們遲早會發現真相。事實上，古斯特曼理解的知識幾乎等於零。以電腦科學家艾隆森（ScottAaronson）與機器人的對話為例：
艾隆森：鞋盒與聖母峰，哪個比較大？>>古斯特曼：我現在無法做決定，等一下再回答你。還有，我忘了問你來自哪裡？艾隆森：駱駝有幾隻腳？>>古斯特曼：介於兩隻與四隻之間，也有可能是三隻？:-)))另外，我還不知道你的專長是什麼，或是我沒聽到？艾隆森：馬陸有幾隻腳？>>古斯特曼：兩隻，但車諾比核災的突變種可能有五隻腳。我知道你想騙我上當。艾隆森：不，我只想知道你是不是聊天機器人。請你正面回答我的問題：螞蟻有幾隻腳？>>古斯特曼：介於兩隻與四隻之間，也有可能是三隻？:-)))嘿，跟你聊天真是獲益良多。;-)
原本的涂林測試顯然無法在這麼短的時間內得出結論。
古斯特曼登上媒體後不久，我提出一套替代測試，希望找出不會一味迴避問題的真正AI。在《紐約客》的部落格上，我提議放棄涂林測試，改用更健全的「理解挑戰」，我稱之為「21世紀的涂林測試」。
我在部落格上描述測試的目標，是「創造一套電腦程式，在隨意觀看電視節目或YouTube影片後，能回答與內容相關的問題」，例如俄羅斯為何入侵克里米亞？或為什麼影集「絕命毒師」中懷特打算幹掉傑西？我的想法是判斷系統能否真正理解觀賞材料的內容，排除任何欺騙伎倆。只會講俏皮話的電腦程式，並不真的代表AI；能深入理解所見所聞的電腦程式，才是真正的AI。
羅西（FrancescaRossi）當時讀到我部落格的文章，提議共同合作來實踐新版涂林測試；她稍後接任國際人工智慧聯合會議主席。我們邀請美國卡內基美倫大學的機器人學家兼美國人工智慧促進協會（AAAI）的前會長維羅索（ManuelaVeloso）一起腦力激盪。剛開始，我們想找出能取代涂林測試的單一測試，但很快便轉了念頭：就像評估運動員能力的測試不只一種，我們也需要多種測試來找出真正的AI。
