讓電腦說人話 : 讓電腦像人般說話，機器就能把語言的意義傳達得更動人。
今天，打電話到任何具規模的公司，一開始大概都得和電腦來段對話。直到最近，這類電話自動語音系統還是只能把預錄好的字詞串連在一起。想想看那些機械化的聲音：「您所撥的號碼是……五……五……五……一……二……一……二……」遺憾的是，這種呆板的電腦語音只會讓人覺得冷漠，而且能說的內容不脫預錄好的罐頭詞彙，功能因此受限。
電腦語音在過去10年裡進步不少，變得更加易懂、易聽。不過研究人員現在卻得面對更驚人的挑戰：讓合成語音更像真人在說話，比如賦予它可調整聲調與情緒的能力，如此一來，就能把意思傳達得更好。想達成這項艱鉅的目標，必須先深入了解話語的組成元素，以及人類的音量、音調、說話速度與重音所造成的微妙效果。這正是我們IBM研究小組的目標，也是美國其他公司與學術機構內研究人員的目標，包括：AT&T、Nuance、Cepstral、掃描軟體（ScanSoft）、卡內基美倫大學、加州大學洛杉磯分校、麻省理工學院與俄勒岡研究學院等。最新一代的語音技術就像早期的詞語剪接（phrasesplicing）方法，也是以預錄好的人聲做為基礎，並可即時回應，我們的技術版本代號為「IBM自然情緒語音合成器」（IBMNaturalExpressiveSpeechSynthesizer），或簡稱為「NAXPRES合成器」。不同的是，新系統可以自然地說出任何話語，包括預錄人員不曾錄下的。
全球各地的公司行號與學術機關，每年花在語音資訊服務中心上的經費高達數十億美元。這些語音中心所用的技術包括：語音辨識、語言理解、資料庫搜尋與文字生成，最後才是語音合成。合成的語音是由真人預錄好的字彙或字串所連結而成，可說是整個系統的化身或人類象徵。因此，人們經常根據聽到的聲音品質來判斷系統的好壞。舉例來說，當你在預約時，系統如果能夠根據預約的成功與否，適當的調整音調，來電者應該會覺得比較愉快而且印象深刻。
快速發展的語音技術所促成的各種新服務，很快將惠及消費者，其中包括以語音播送即時新聞與氣象預報，取代原本只能以文字形式呈現的訊息。這項技術也能不休止地為殘障人士或只懂外語的學生朗讀書面資料。其他有用的功能還有語音式的人機互動，可控制汽車運作，包括含有全球數百萬街道名稱的口述自動駕駛命令；或是在無需顯示器的狀況下，用電話或其他資訊系統接收電子郵件。
自然合成語音技術遲早會在手持式或家用器材上，發出有意義的聲音。而且終有一天，這項科技會用在影片、電玩或甚至動畫上，為其中的角色配上栩栩如生的聲音。
機器在說話
合成語音不僅是科技上的勝利，也是古老夢想的最新實踐。模擬人聲的企圖可回溯到18世紀晚期。當時匈牙利科學家肯普蘭（WolfgangvonKempelen）利用一系列精巧的風箱、蘆葦桿、風笛與共鳴箱，製造出可發出簡單語彙的機器，取名為「說話機」（SpeakingMachine）。
到了1970年代，第一代的現代文字轉語音（text-to-speech）系統，隨著數位運算而受到相當廣泛的應用。這些系統的製造者企圖利用相當少數的參數特徵，直接模擬出人類發聲的整個生理過程。一般而言，這種模型具有一個音源，負責扮演人類喉部的角色；另外還有個濾音器，可做為人類發聲管道的其餘部份。這種系統可不斷調整聲音的物理性質（共振、頻寬、週期與基本頻率），製造所需的聲音序列，以組合出語音。
最後的結果雖然聽起來頗為機械化，卻是人類可理解的語音。最早採用這項技術的大眾化商品之一，就是1978年上市的玩具Speak&Spell。這類合成器容易製作，而且能以極快的速度發出可理解的語音，每分鐘高達600個字（英語交談的一般速度為每分鐘140~190個字），因此仍然在今日的市場佔有一席之地。那些願意以自然語音換取速度的人，好比視障人士，就會覺得這些系統相當實用。
1990年代末，更快的電腦與廉價的資料儲存空間出現了，連帶促成今天最先進的合成器的誕生。包括我們IBM小組在內的研究人員在設計時，都是以語言學上的最小單位「音素」為基礎，並且把預錄的音素拿來排列組合，以製造特定單字的語音。好比school這個字，就包含了四個音素，姑且稱之為S、K、OO與L。不同的語言所含有的音素多寡也不同。英語大約使用了40個不同的音素，日語的音素大約有25個，德語則有44個。就像過去的排版系統會把金屬字母排列在字盤上印出文字一樣，現在的合成器也能把語音片段組合在一起，製造出話語。工程師把這類系統稱為連續式（concatenative）合成器，因為它們能把小小的語音片段串連在一起。接下來將解釋我們如何建立這樣的系統，並且描述合成器如何即時產生栩栩如生的語音。
