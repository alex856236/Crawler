機器如何深度學習 : 人工智慧經歷數十年的低潮，由於深度學習這項潛力無窮的技術，總算起死回生，在不少任務上的表現已經相當傑出。
重點提要■1950年代，人工智慧（AI）開始成為學術研究的一個新領域，研究人員希望在一個世代內成功展現人類智慧。不過當時的演算法和計算能力無法勝任，夢想也隨之破滅。■過去幾年，AI研究捲土重來。研究人員從腦科學汲取靈感，發展深度學習技術。這些模仿大腦神經網路的演算法證明，先前對於AI的期望或許能夠實現。■深度學習技術透過複雜的人工神經網路，接收各種範例進行學習，例如辨識影像、聽懂語音、進行棋類比賽，而且在某些任務上的表現已經相當接近人類智慧。
1950年代，電腦開始在西洋棋上戰勝人類，並且協助數學家證明數學定理，人們為此興奮不已。1960年代，人們的期望越來越高，覺得科學家很快就會在軟硬體上展現人類智慧、人工智慧（artificialintelligence,AI）在各種任務上的表現也不會輸給人類。1967年，美國麻省理工學院（MIT）的明斯基（MarvinMinsky，今年初過世）宣稱，AI的挑戰將在一個世代內解決。
當然，這種樂觀看法顯然言之過早。不論是透過軟體協助醫師做出更準確的診斷，或是藉由網路仿效人腦來辨識影像的內容，這些事都無法符合人們原先的期望。早年的演算法不夠成熟，也缺少大量資料來執行運算。我們想讓機器呈現宛若高度智慧的人類思維，機器就必須執行大量的計算，但當時的電腦處理能力實在太「溫吞」了。
到了2000年代中期，打造擁有人類等級智慧的機器這類夢想幾乎在科學社群中消失了，甚至連AI這個詞也淡出科學領域。科學家和媒體把1970年代到2000年代中期的希望破滅稱為「AI寒冬」。
但最近這10年，情況大為不同。從2005年開始，AI的前景有了劇烈轉變，因為「深度學習」（deeplearning）從那時開始發揮作用。深度學習是一種從腦科學汲取靈感以打造智慧機器的方法，最近幾年已經成為推動AI研究的主力，大型資訊科技公司都投資了幾十億美元進行研發。
深度學習是指模擬生物神經元的網路「學習」辨識影像、聽懂語音，甚至自行做決定。這項技術依賴所謂的「人工神經網路」（artificialneuralnetwork），這是現今AI研究的主要方法。人工神經網路不會完全模仿生物神經元的運作方式，相反地，它是基於一般的數學原理，從範例中學習辨識影像中的人或物體，或是翻譯世界上主要的語言。
深度學習技術已經改變了AI研究，重啟人們對電腦視覺（computervision）、語音辨識、自然語言處理與打造機器人的野心。第一個聽懂人類語音的產品在2012年問世，就是有些人常用的軟體GoogleNow；沒多久，辨識影像內容的應用程式也推出了，現在這項功能已經整合在Google相簿的搜尋引擎。
覺得電話自動化選單難以操作而感到沮喪的人，應該會喜歡在智慧型手機上使用個人語音助理（例如Siri）來完成這件事。回想幾年前，軟體辨識物體的功能仍不理想，可能把石頭誤認成人臉，但電腦視覺已經大幅進步，令人驚豔。在特定情況下，現在的電腦幾乎和人類一樣能辨識影像中的貓、石頭或人臉。事實上，在數百萬智慧型手機使用者的生活中，AI軟體已經不可或缺。例如，我已經很少以手寫或打字方式寫簡訊，更常透過語音輸入。
這些進步敞開了深度學習邁向商業化的大門，而且這股熱潮只會日益高漲。各家公司開始尋覓高手，專攻深度學習的博士現在是炙手可熱的稀有人才。根據一些報告，產業界從學術界挖角了很多擅長這領域的大學教授，並提供完善的研究設備和豐厚的待遇。
科學家不但克服深度學習的挑戰，更讓世人留下了深刻印象。AlphaGO在圍棋比賽中打敗韓國一流棋手李世，各媒體都以頭條新聞報導這起事件。相關應用更擴展到其他專業領域，據說一套新研發的深度學習演算法，能和心臟病學家一樣從磁共振造影（MRI）診斷出心臟衰竭。
