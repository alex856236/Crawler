機器人也懂倫理 : 不久之後，擁有自主能力的機器人就會在我們的生活中扮演重要角色，但是在此之前，它們要先學會遵守規範才行。
重點提要■可自主做出決定的機器人，例如用於協助老人生活的機器人，即使在看似平常的狀況下，也可能面臨倫理困境。■確保機器人能以合乎倫理的行為與人類互動的方法之一，是將一般倫理原則輸入機器人，並讓機器人在各種狀況下運用這些原則做出決定。■人工智慧技術可借助邏輯，由各種倫理上可接受的行為案例中，自行歸納、產生原則。■本文作者依據此方法，把程式寫到機器人裡，做出第一個依據倫理原則行動的機器人。
機器人聰明到足以挑戰人類，是驚悚科幻小說裡常見的恐怖情節，而且機器人絕對不會因為傷害甚至毀滅人類而感到絲毫內疚。當然，目前機器人的用途大多是幫助人類，但即使在相當平常的狀況下，機器人也會面臨許多倫理上的挑戰，而人工智慧也不斷在突破這些困境。
想像一下，機器人可能很快就會出現在安養機構，而你就住在安養機構裡。接近上午11點時，你要娛樂室裡的機器人幫你拿遙控器，好讓你打開電視收看「超級星光大道」。但另一位住客也想拿遙控器，因為她想看「全民估價王」，最後機器人決定把遙控器拿給她。剛開始你有點不高興，但機器人解釋這個決定很公平，因為你今天已經看過你最喜歡的晨間節目。這個故事是很平常的倫理決策行為範例，但對於機器人而言，卻是十分難以達成的重大成就。
前面描述的狀況只是理論上的模擬，但我們已經製作出第一款能做出類似決定的示範機器人。我們賦予這具機器人倫理原則，讓它能依照這個原則決定該隔多久提醒病患吃藥。機器人的程式目前只能從少數幾種可能的選項中選取其中之一，例如是否要一直提醒病患吃藥與何時該提醒，或是什麼狀況下該接受病患不吃藥的決定，不過就我們所知，這是第一款依據倫理原則決定行動的機器人。
但要預測機器人可能面臨的所有抉擇，並將之寫入程式，讓機器人在各種想像得到的狀況下都能妥善處理，卻相當困難，可以說是不可能。但另一方面，如果完全不讓機器人採取需要做出倫理抉擇的行動，又可能限制機器人執行得以大幅改善人類生活的任務。我們認為，解決方法是讓機器人能將倫理原則運用在預料之外的新狀況下，好比說除了判斷該讓誰拿遙控器之外，還可以決定該讓誰看新書等。這種方式還有一個優點，就是當機器人被要求解釋自己的行為時，可以參考這些原則。如果要讓人類自在地與機器人互動，這點十分重要。另外一個附加優點則是，倫理機器人的開發工作，也可促使哲學家探究日常生活狀況，帶動倫理學這個領域本身的進步。就像美國塔弗茲大學哲學家鄧奈特（DanielC.Dennett）最近說過的：「人工智慧使哲學更誠實。」
【欲閱讀更豐富內容，請參閱科學人2010年第105期11月號】
